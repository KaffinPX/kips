```
  KIP: 5
  Layer: Consensus (hard fork), Block Validation
  Title: Proofs of Validation (PoV) and Proofs of Chain Membership (PaChM)
  Author: Shai Wyborski <shai.wyborski@mail.huji.ac.il>
  Status: proposed
```

# Motivation
The pruning mechanism makes it impossible to prove that a transaction was included in the ledger after it has been pruned. The only currently available solution is publicly run archival nodes (in the form of block explorers) that store all historical data. However, this is not a sustainable solution, since the size of the databases increases rapidly with time and adoption.

A better solution is to provide a *cryptographically verifiable proof* that a transaction was posted to the blockchain. Such a proof could only be *generated* before the transaction was pruned (or by using an archival node), but could be *verified* indefinitely.

We consider two types of proof: a *proof of publication* (PoP) and a *proof of validation* (PoV). The first kind only proves that a transaction was present on the blockDAG at some point, whereas the second proves that a transaction was *accepted*. That is, while a proof of publication can prove that ``txn`` was posted to the blockchain, it can not discount the scenario where a *conflicting* transaction ``txn'`` was also posted and that ``txn'`` was validated while ``txn`` was discarded.

In this KIP I will mostly concentrate about proofs of validation. It is possible to obtain a PoP that is slightly smaller, but the difference is so marginal I propose to use a PoV even in contexts where a PoP is sufficient.

The current state of the art is that it is technically possible to obtain proofs of validation, but such proofs can grow rather large (up to about 24 megabytes in the worst case), and there is no API call for generating such a proof. I describe a small modification to the block validation rules that extremely reduces the size of a proof of validation (down to about 9.5 kilobytes in the worst case) while incurring very mild costs on the performance of the network (in terms of header size and block validation complexity). I also provide a precise algorithmic descriptions of how such a proof is generated and verified, with the intention that they will be implemented as API calls.

I stress that the current sizes are calculated with respect to the values of various parameters in the current 1BPS consensus. Changing these parameters would require recalculating these values. However, increasing block rates will only increase the factor by which proposed proofs are improve upon currently possible proofs (roughly because currently possible proofs are as large as the entire ledger stored between two consecutive pruning blocks, whereas the size of proposed proofs grows *logarithmically* with the number of *chain blocks* between two consecutive pruning blocks. In particular, increasing BPS will increase the size of current proofs, but not the size of proposed proofs).

# Notations

In this proposal, it is convenient to use the notation ``Past(B)`` (resp. ``Future(B)``) to denote the past (resp. future) of the block ``B`` *including* the block ``B`` itself. The method names are capitalized to differentiate them from the common notations ``past(B)`` and ``future(B)`` which *exclude* the block ``B`` itself.

I use the notation ``parent(B,n)`` to note the *nth selected parent* of ``B``. For brevity, I use ``parent(B)`` instead of ``parent(B,1)``. For any ``n>1`` we can recursively define ``parent(B,n)=parent(parent(B,n-1))``.

# Stored Headers

Currently, the Kaspa node stores a block header from the selected chain once every 24 hours. The stored headers are those of previous pruning blocks, however, this is irrelevant in the context of the current proposal, so I will refer to them as `stored headers` to avoid confusion.

Stored headers have the following important properties:
 * They are determined in consensus. That is, all nodes stores the same sets of headers
 * They are headers of blocks in the *selected chain*
 * Each selected header contains a pointer to the next selected header. Hence, the chain of selected headers is verifiable all the way down to genesis. In particular, obtaining and verifying this chain is part of the process of syncing a new node.

Given a block ``B`` let ``stored_header(B)`` be the *earliest* stored header that is either ``B`` or has ``B`` in its past. If such a stored header does not exist yet, output ⊥. Let ``stored_depth(B)`` output the integer ``n`` satisfying ``B=parent(stored_header(B),n)`` (or ⊥ if stored_header(B)=⊥).

For any block ``B`` let ``next_stored_header(B)`` be the header of the block with the following property: if ``B`` is a stored header, then ``next_stored_header(B)`` is the next stored header. Note that this is well defined even if ``B`` is not a stored header.

# Accepted Transactions Merkle Root (ATMR)

In Bitcoin, every header contains the root of a Merkle tree of all transactions included in this block. In Kaspa, this Merkle tree is extended to contain all *accepted* transactions included in this block *and its merge set*. That is, all transactions that appear either in the block or the merge set of the block, except transactions that conflict other transactions that precede them in the GHOSTDAG ordering. 

# Proofs of Chain Membership (PoChM)

In order to provide a proof that ``txn`` was validated it suffices to provide the following:
 * A header of a block ``B`` and a Merkle proof that ``txn`` appears in ``B``'s (ATMR)
 * Proof that ``B`` appeared in the selected chain

This suffices to prove that ``txn`` was validated even if a conflicting transaction ``txn'`` (or any number thereof) was also included in the blockDAG: the validation rules imply that ``txn`` and ``txn'`` both appeared in the anticone of ``B``, and that ``txn`` preceded ``txn'`` in the GHOSTDAG ordering.

The first item is a straightforward Merkle proof. However, the second item is trickier. I refer to such a proof as a *proof of chain membership* (PoChM, pronounced like the Latin word *pacem*) for ``B``. The rest of this document is concerned with providing a PoChM for an arbitrary block ``B``.

# PoChM Without Hard-Fork

Currently, the most straightforward way to construct a PoChM for ``B`` is to store the entire set ``Future(B) ∩ Past(stored_block(B))``. The result is a "diamond shaped" DAG whose only source is ``stored_block(B)`` and only sink is ``B``. Given a DAG of this shape as proof, any node could verify that its source is a known stored header, that its sink is *B*, and that starting with the source and following the selected parents leads to the sink.

The problem with this proof is its size. In the worst case, it would be about as large as 24 hours worth of headers. At the current 1BPS and header size of 248 bytes, this sums to about 24 megabytes.

Remark: This could be improved slightly by, instead of storing the entire set, only storing the headers of the selected chain blocks and their parents. This data suffices to compute the selected parent of each selected chain block and validate the proof. However, this does not seem to improve the size by much. Also note that proofs for many transactions that were accepted in chain blocks with the same ``stored_block`` can be aggregated. In particular, a PoChM for a block B is also a PoChM for any chain block ``C ∈ Future(B) ∩ Past(stored_block(B))``

# Performance trade-offs

Our goal is to decrease the size of a PoChM as much as possible while minimizing performance costs. There are two relevant types of costs: header sizes, and block validation complexity.

As an extreme example, one could provide a very small PoChM by including in each stored header the entire list of headers of all chain blocks down to the next stored header. This "solution" is obviously prohibitive as it will make block headers huge.

On the other extreme, one could include in each header a *Merkle tree* of all chain blocks down to the next stored header, and let the PoChM of B be a Merkle proof for that tree. While this "solution" only increases the size of a block header by 32 bytes (the size of a single hash), it makes it necessary to compute tens of thousands of hashes to validate a single block header, which is prohibitively costly.

Our proposal "balances" the second approach: we add to each header the root of a Merkle tree that only contains *logarithmically many* headers, this allows to generate a PoChM in the form of a logarithmically long chain of headers and Merkle proofs.

In the current parametrization, implementing our propoasl requires increasing the size of a header by a single hash (32 bytes), and adds a validation step with constant space complexity and a time complexity of θ(log(N)) where N is the number of *chain* blocks between two consecutive stored blocks. The size of a PoChM, as well as the time required to verify it, is θ(log(N)loglog(N)).

We will provide non-asymptotic bounds after specifying the solution. For now we will state that in the current parametrization, the new block validation step requires computing 33 hashes (and can be skipped for blocks outside the selected chain), and that, in the worst case, the size of a PoChM is about 9.5 kilobytes.

# Uniform Validation Complexity

In theory, we could have defined our result such that the new validation step only applies at blocks chosen to be stored blocks. However, this makes stored blocks harder to construct and verify compared to other blocks. This might significantly increase their propagation time, decentivize miners from mining them, or have other unexpected adverse effects. To avoid this, we propose requiring all blocks to pass this verification step.

# Our Proposal

The block header will contain a new field called the *PoChM Merkle root* (PMR) defined as follows: let k be the least integer such that ``parent(B,2^k) ∈ Past(next_stored_header(B))``, then PMR is the root of the Merkle tree containing the headers ``parent(B,2^i)`` for ``i = 0,...,k-1``.

Let ``PMR(B,i)`` be the function that outputs a Merkle proof that ``hash(parent(B,2^i))`` is in the tree whose root is the PMR of B.

The process of header validation of chain block candidates will include verifying the PMR. I propose that the PMR will not be validated for blocks that are not chain candidates. In particular, a block whose PMR is invalid but is otherwise valid will remain in the DAG but will be disqualified from being a selected tip/parent. A similar approach is employed when validating (can't remember what that is (bounded merge?), remind myself and add a link).

The procedure for generating a *PoChM* for a block ``B`` is as follows:
     
    Let C = stored_block(B)
    If C=⊥ output ⊥
    Let d = stored_depth(B)
    Let proof = []
    While true:
          Let i = floor(log_2(d))
          proof.append(PMR(C,i))
          d -= 2^i
          If d == 0:
              Break
          C = parent(C,2^i)
          proof.append(C)
     Return proof

To understand how to validate the proof we first consider it in two simple cases:

If there is some i such that ``stored_depth(B) = 2^i`` then ``B`` itself is a member of the PMR of ``stored_block(B)`` and the entire PoChM is a single Merkle proof.

If there are some i>j such that ``stored_depth(B) = 2^i + 2^j`` then the proof would contain three items:
 * A Merkle proof that ``hash(parent(stored_header(B),2^i))`` is in the PMR of ``stored_header(B)``
 * The header ``parent(stored_header(B),2^i)`` (that in particular includes its PMR)
 * A Merkle proof that ``hash(B)`` is in the PMR of ``parent(stored_header(B),2^i)``

By verifying the proofs and hashes above, one verifies that ``B`` is indeed a chain block. The general procedure extends similarly.

# Size of PoChM

Letting ``L_e`` and ``L_a`` denote the size of a header and a hash respectively, and letting ``N`` denote the maximal size of the number of chain blocks between two consecutive stored headers, we find that the size of each Merkle proof is at most ``(2*loglogN+1)*L_a``, and at most ``logN`` of them are required. Also, at most ``(logN-1)`` headers are required. Hence, the total size of the PoChM is at most ``(logN-1)L_e + logN(2*loglogN+1)L_a``. In the current parametrization, this bound turns up to be about 9.5 kilobytes.

However, this bound was computed assuming *all* blocks are in the selected chain. In practice, a (hard to predict) fraction of them is in the selected chain. By starting at the KGI for a while, one can get convinced that in reality about two fifths of the blocks are in the selected chain, so it is more reasonable to expect the proof size to be around 4 kilobytes in the worst case and 2 kilobytes in the average case.

Notably, increasing the BPS does not increase the size of the PoChM, since this increases the *width* of the graph and not the length of the selected chain. Hence, I do not expect the increase to 10BPS to affect the size of the proposed PoChM (which stands in stark contrast to the currently possible PoChM).

Interestingly, what *will* increase the size of the proposed PoChM is an improvement in network conditions, as better connectivity means that the blocks better align in a chain-like structure. However, this is not an actual concern since the size of the proof is still dominated by very mild log*loglog asymptotics.
            
# Stored Header Density

As a final optimization, I propose increasing the stored block density to once an hour. The main motivation for this optimization is to reduce the time required before a PoChM could be generated. A prerequisite for generating a PoChM is that stored_header(B) already exists, and reducing this time is beneficial. Additionally, this would meaningfully reduce the complexity of the added verification steps, of PoChM verification and, most notably, the size of a PoChM might decrease to as little as half a kilobyte.

The cost of storing a header once per hour (taking into account the added hash) increases the storage requirement by 2.5 megabytes per *year*, which is negligible.

# Backwards compatibility
Breaks consensus rules, requires hardfork. Changes header structure.
